{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GCP_API.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YG1YQ0ICvvJO","colab_type":"code","colab":{}},"source":["import os\n","import base64\n","import requests\n","from IPython.display import display, Image\n","from google.colab import files\n","\n","pAPI_KEY='AIzaSyA2Vz75LKUi0HVj5P87vx1jAKLJzMCcDE8'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FdjvA4OwbXp","colab_type":"code","colab":{}},"source":["os.environ['API_KEY']=pAPI_KEY\n","!echo \"$API_KEY\"\n","# Another way of assigning env Var\n","#%env API_KEY=AIzaSyB1UlDyJgdXhvYkRJOUPMjo-fUG62_c1w8"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOUBQPIyOlZO","colab_type":"text"},"source":["## Load the image file from your local machine to see what GCP thinks are in the picture\n","Click \"Choose Files\" button and select the file from your local machine"]},{"cell_type":"code","metadata":{"id":"tm9gYkqvzFlG","colab_type":"code","colab":{}},"source":["!wget https://whc.unesco.org/uploads/thumbs/site_0252_0001-500-375-20080319163058.jpg"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYUu5QLTzWMu","colab_type":"code","colab":{}},"source":["display(Image(filename=\"site_0252_0001-500-375-20080319163058.jpg\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BOC151j40GQU","colab_type":"code","colab":{}},"source":["image_file=open(\"site_0252_0001-500-375-20080319163058.jpg\", 'rb')\n","images = image_file.read()\n","visionJson={\n","  \"requests\": [\n","      {\n","        \"image\": {\n","           \"content\": base64.b64encode(images).decode(\"UTF-8\")\n","        },\n","        \"features\": [\n","          {\n","            \"type\": \"LANDMARK_DETECTION\",\n","            \"maxResults\": 10\n","          }\n","        ]\n","      }\n","  ]\n","}\n","visionResp = requests.post('https://vision.googleapis.com/v1/images:annotate?key={0}'.format(pAPI_KEY), json=visionJson)\n","print(visionResp.text)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nVhLTH0ImJtl","colab_type":"text"},"source":["##Load your own picture here"]},{"cell_type":"code","metadata":{"id":"c-295mIjNHT1","colab_type":"code","colab":{}},"source":["uploaded = files.upload()\n","# Keep only the last file for vision recognition\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  filename = fn\n","\n","  with open(filename, 'rb') as image_file:\n","    images = image_file.read()\n","display(Image(filename=filename))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkwJj532oEyN","colab_type":"code","colab":{}},"source":["visionJson={\n","  \"requests\": [\n","      {\n","        \"image\": {\n","           \"content\": base64.b64encode(images).decode(\"UTF-8\")\n","        },\n","        \"features\": [\n","          {\n","            \"type\": \"LABEL_DETECTION\",\n","            \"maxResults\": 10\n","          }\n","        ]\n","      }\n","  ]\n","}\n","\n","visionResp = requests.post('https://vision.googleapis.com/v1/images:annotate?key={0}'.format(pAPI_KEY), json=visionJson)\n","print(visionResp.text)\n","#raise Exception(\"Stop to look at the results!!!\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sRmi5zduYJhj","colab_type":"text"},"source":["##Upload image and try facial recognition and landmark identification"]},{"cell_type":"code","metadata":{"id":"t3B4ZNNlYKNV","colab_type":"code","colab":{}},"source":["uploaded = files.upload()\n","# Keep only the last file for vision recognition\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  filename = fn\n","\n","  with open(filename, 'rb') as image_file:\n","    images = image_file.read()\n","display(Image(filename=filename))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOW342P6XCbv","colab_type":"code","colab":{}},"source":["faceJson={\n","  \"requests\": [\n","      {\n","        \"image\": {\n","           \"content\": base64.b64encode(images).decode(\"UTF-8\")\n","        },\n","        \"features\": [\n","          {\n","            \"type\": \"FACE_DETECTION\"\n","          },\n","          {\n","            \"type\": \"LANDMARK_DETECTION\"\n","          }\n","        ]\n","      }\n","  ]\n","}\n","\n","faceResp = requests.post('https://vision.googleapis.com/v1/images:annotate?key={0}'.format(pAPI_KEY), json=faceJson)\n","print(faceResp.text)\n","\n","raise Exception(\"Stop to look at the results!!!\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"USaARDJVY2Ui","colab_type":"text"},"source":["##Upload Image and try character recognition"]},{"cell_type":"code","metadata":{"id":"TfXR_w-SZYUB","colab_type":"code","colab":{}},"source":["uploaded = files.upload()\n","# Keep only the last file for vision recognition\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  filename = fn\n","\n","  with open(filename, 'rb') as image_file:\n","    images = image_file.read()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcqJW4BtY244","colab_type":"code","colab":{}},"source":["textJson = {\n","  \"requests\": [\n","      {\n","        \"image\": {\n","           \"content\": base64.b64encode(images).decode(\"UTF-8\")\n","        },\n","        \"features\": [\n","          {\n","            \"type\": \"TEXT_DETECTION\",\n","            \"maxResults\": 10\n","          }\n","        ]\n","      }\n","  ]\n","}\n","\n","textResp = requests.post('https://vision.googleapis.com/v1/images:annotate?key={0}'.format(pAPI_KEY), json=textJson)\n","print(textResp.text)\n","\n","raise Exception(\"Stop to look at the results!!!\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j1kbhvAiZ8bJ","colab_type":"text"},"source":["##Try translation API\n"]},{"cell_type":"code","metadata":{"id":"gEusi4jndVA_","colab_type":"code","colab":{}},"source":["import json\n","loaded_json = json.loads(textResp.text)\n","extract = loaded_json['responses'][0]['textAnnotations'][0]['description']\n","transJson = {\n","  \"q\": \"{}\".format(extract),\n","  \"target\": \"en\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xyL999EZ78Y","colab_type":"code","colab":{}},"source":["resp = requests.post('https://translation.googleapis.com/language/translate/v2?key={0}'.format(pAPI_KEY), json=transJson)\n","print(transJson)\n","print(resp.text)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p5BaX_NzoWsx","colab_type":"text"},"source":["## Speech API"]},{"cell_type":"markdown","metadata":{"id":"6Rv-EETEtJNe","colab_type":"text"},"source":["      \"languageCode\": \"hi-IN\"\n"]},{"cell_type":"code","metadata":{"id":"B_4lBmsHoado","colab_type":"code","colab":{}},"source":["speech_json = {\n","  \"config\": {\n","      \"languageCode\": \"en-US\"\n","  },\n","  \"audio\": {\n","      \"uri\":\"gs://piwagoshi/brand.wav\"\n","  }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"exW9Ajgdsyue","colab_type":"code","colab":{}},"source":["resp = requests.post('https://speech.googleapis.com/v1/speech:recognize?key={0}'.format(pAPI_KEY), json=speech_json)\n","print( resp.text )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5MePIyk_pcv","colab_type":"text"},"source":["###Import your own speech"]},{"cell_type":"code","metadata":{"id":"1SA0z8fEvZ72","colab_type":"code","colab":{}},"source":["uploaded = files.upload()\n","# Keep only the last file for vision recognition\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  filename = fn\n","\n","  with open(filename, 'rb') as speech_file:\n","    speech_content = base64.b64encode(speech_file.read()).decode(\"UTF-8\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxltjhSMu2AU","colab_type":"code","colab":{}},"source":["speech_json = {\n","  \"config\": {\n","      \"languageCode\": \"en-US\"\n","  },\n","  \"audio\": {\n","      \"content\": speech_content\n","  }\n","}\n","resp = requests.post('https://speech.googleapis.com/v1/speech:recognize?key={0}'.format(pAPI_KEY), json=speech_json)\n","print( resp.text )"],"execution_count":0,"outputs":[]}]}